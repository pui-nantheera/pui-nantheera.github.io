  <!DOCTYPE html>
  <html lang="en">

  <head>
    <meta charset="UTF-8">
    <title>Pui's webpage</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="stylesheet" href="./css/style.css">
    <link rel="apple-touch-icon" sizes="180x180" href="favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicon_io/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@puinantheera">
    <meta name="twitter:title" content="Pui's research highlights">
    <meta name="twitter:description" content="I am an Associate Professor in Visual Computing at the University of Bristol. Here's a showcase of my research.">
    <meta name="twitter:image" content="https://pui-nantheera.github.io/card_social.jpg">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XM2FWS366V"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-XM2FWS366V');
    </script>
  </head>

  <body id="page-top">
    <div class="page-container">
      <div class="inner">
        <div class="container">
          <div class="row">
            <div class="row vertical-align">
              <div class="col-md-3">
                <div class="title">
                  <p><img src="pui_v2.jpg" width="100%" height="20%" class="center" /></p>
                </div>
              </div>
              <div class="col-md-6">
                <div class="title">
                  <h1>Dr Nantheera Anantrasirichai <span style="color: #06837e;">(Pui)</span></h1> 
                  <h5>Associate Professor in Visual Computing</h5>
                  <p>3.20, Merchant Venturers Building, University of Bristol</p>
                  <p>Bristol, BS8 1UB, UK</p>
                  <pre>eexna*at*bris.ac.uk</pre>
                  <ul class="list-inline list-social-icons mb-0">
                    <li class="list-inline-item">
                      <a href="https://scholar.google.com/citations?user=40VEYswAAAAJ&hl=en" target="_blank">
                        <span class="fa-3x">
                            <i class="ai ai-google-scholar-square"></i>
                        </span>
                      </a>
                    </li>
                    <li class="list-inline-item">
                      <a href="https://twitter.com/puinantheera" target="_blank">
                        <span class="fa-3x">
                          <i class="fab fa-twitter-square"></i>
                        </span>
                      </a>
                    </li>
                    <li class="list-inline-item">
                      <a href="https://uk.linkedin.com/in/nantheera-anantrasirichai-389243107/" target="_blank">
                        <span class="fa-3x">
                            <i class="fab fa-linkedin"></i>
                        </span>
                      </a>
                    </li>
                    <li class="list-inline-item">
                      <a href="https://github.com/pui-nantheera">
                        <span class="fa-3x">
                            <i class="fab fa-github-square"></i>
                        </span>
                      </a>
                    </li>
                    <li class="list-inline-item">
                      <a href="https://research-information.bris.ac.uk/en/persons/n-anantrasirichai">
                        <span class="fa-3x">
                            <i class="ai ai-cv-square"></i>
                        </span>
                      </a>
                    </li>
                  </ul>
                </div>
              </div>
              <div class="col-md-3">
                <p><a href='https://www.bristol.ac.uk' target="_blank"><img src="uob-logo.svg" width="100%" height="20%" alt=""></a></p>
                <p><a href='https://www.bristol.ac.uk/vision-institute' target="_blank"><img src="BVI_colour.svg" width="100%" height="20%" alt=""></a></p>
                <p><a href='https://vilab.blogs.bristol.ac.uk' target="_blank"><img src="VIL_logo.svg" width="100%" height="20%" alt=""></a></p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-md">
          <h2>About</h2> 
          <p>I am an Associate Professor in the School of Computer Science at the University of Bristol (UoB) and a member of the <a href="https://vilab.blogs.bristol.ac.uk" target="_blank">Visual Information Laboratory</a>, led by <a href="https://research-information.bris.ac.uk/en/persons/alin-achim">Prof. Alin Achim</a>, and the <a href="https://www.bristol.ac.uk/vision-institute">Bristol Vision Institute</a>, led by <a href="https://david-bull.github.io/">Prof. David Bull</a>. 
          I have been involved in many projects across multiple disciplines, including telecommunications, biology, optometry, clinical sciences, biochemistry, mechanical engineering, psychology and geoscience. I lead a work package, AI Workflows for Challenging Acquisition Environments, as part of <a target="_black" href="https://www.myworld-creates.com/">MyWorld</a>, strengthening the world-leading position of creative technologies in the southwest region. Additionally, I am a key scientist at the Centre for the Observation and Modelling of Earthquakes, Volcanoes, and Tectonics (<a target="_black" href="https://comet.nerc.ac.uk/">COMET</a>). </p>

          <p>I am a Programme Director of <a target="_blank" href="https://www.bristol.ac.uk/study/postgraduate/2023/eng/msc-immersive-technologies-virtual-and-augmented-reality/">MSc Immersive Technologies (Virtual and Augmented Reality)</a>. During the 2024/2025 academic year, I will be on a University Research Fellowship and therefore will not be involved in teaching. For any inquiries regarding <a target="_black" href="https://www.bris.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=24%2F25&unitCode=COMS30030">Image Processing and Computer Vision</a> (Y3), <a target="_black" href="https://www.bristol.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=24%2F25&unitCode=COMSM0159">Advanced Visual AI </a> (Y4), and <a target="_black" href="https://www.bristol.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=24%2F25&unitCode=COMSM0127">Immersive Interaction and Audio Design</a>  (PGT), please contact the respective Unit Directors.<!--, a Unit Director of <a target="_black" href="https://www.bris.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=24%2F25&unitCode=COMS30030">Image Processing and Computer Vision (Y3)</a>, and a Unit Director of <a target="_black" href="https://www.bristol.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=24%2F25&unitCode=COMSM0159">Advanced Visual AI (Y4)</a>. I also teach <a target="_black" href="https://www.bristol.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=24%2F25&unitCode=COMSM0127">Immersive Interaction and Audio Design (PGT)</a> and Computer System (Y2).--></p>
        </div>
        <hr /> 
        <div class="container-md">
          
          <h2>Opportunities </h2> 
          <ul>
            <li><a>Senior Research Associate</a> funded by EPSRC: Project '<a href='phd_offer.html'>Intelligent Video Restoration and Enhancement via a Large Prior Database</a>'</li>

<li><a>PhD Scholarship</a> funded by UoB/EPSRC: Project '<a href='phd_offer.html'>Intelligent Video Restoration and Enhancement via a Large Prior Database</a>'</li>
<li><a>PhD Scholarship</a> funded by UoB: <a href='https://www.bristol.ac.uk/science-engineering/postgraduate-research/pgr-scholarships/'>University of Bristol Postgraduate Research Scholarships</a>. Please send me your CV and transcripts.</li>
</ul>
        </div>
        <hr /> 
        <div class="container">
          <div class="row">
            <div class="row vertical-align">
              <div class="col-md-auto">
                <div class="container-md">
                  <h2>Research Interests</h2>
                  <ul>
                    <li>Image analysis and enhancement</li>
                    <li>Image and video restoration</li>
                    <li>Image fusion</li>
                    <li>Machine learning</li>
                    <li>Inverse problem</li>
                    <li>Remote sensing</li>
                    <li>Medical imaging</li>
                    <li>Image and video coding</li>
                  </ul>
                </div>
              </div>
              <div class="col align-self-start">
                <div class="col-md-auto">
                  <div class="container-md">
                    <h2>Highlights</h2>
                    <ul>
                      <li><a href="https://arxiv.org/abs/2410.01517" target="_blank">UW-GS: Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater Scene Reconstruction</a> and are <a href="https://openaccess.thecvf.com/content/WACV2025W/ImageQuality/papers/Morris_DaBiT_Depth_and_Blur_informed_Transformer_for_Video_Deblurring_WACVW_2025_paper.pdf" target="_blank">DaBiT: Depth and blur informed transformer for video deblurring</a> presenting at WACV2025</li>
                      <li><a href="https://dl.acm.org/doi/pdf/10.1145/3697294.3697304" target="_black">Low-light Video Enhancement with Conditional Diffusion Models and Wavelet Interscale Attentions</a> won the best paper award at ACM SIGGRAPH CVMP</li>
                      <li><a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement" target="_blank">BVI-Lowlight: Fully registered datasets for low-light image and video enhancement</a></li>
                      <li>Updated review paper: <a href="https://arxiv.org/pdf/2501.02725?">Artificial Intelligence in Creative Industries: Advances Prior to 2025</a></li>

                    </ul>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <hr />
        <div class="container">
          <div class="row">
            <div class="row vertical-align">
              <div class="col-md-auto">
                <div class="container-md">
                  <h2 id="projects">News & Activities</h2>
          <ul>
            <li>2025-2027: EURASIP TAC (Second Term) <a href="https://eurasip.org/technical-area-committees/">Biomedical Image & Signal Analytics</a></li>
            <li>April 2025: Invited talk: EGU</li>
            <li>12 Mar 2024: Invited talk: AI for Visual Data at <a href="https://www.bristol.ac.uk/fssl/research/sociodigital-futures/" target="_black">CenSoF</a></li>
            <li>12 Feb 2024: New project! <a href="https://pui-nantheera.github.io/research/CIC/MyUnderwaterWorld.html">MyUnderwaterWorld</a></li>
            <li>31 Oct 2023: New dataset! <a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement" target="_black">BVI-Lowlight</a> Fully registered video dataset</li>
            <li>5 Oct 2023: Invited speaker at <a href="https://www.eventbrite.co.uk/e/bringing-space-down-to-earth-tickets-713655923077" target="_black">Bringing Space Down to Earth</a></li>
            <li>1 Jun 2023: New project! <a href="">Object recognition under heat haze environment</a></li>
            <li>1 Mar 2023: Invited talk <a href="https://camtrapai.github.io/ai_nature_week.html">AI-based Image Processing for Challenging Natural Data</a></li>

          </ul>
          <div class="line_sep"></div>
            Previous News & Activities: <a href="activities.html">see here</a>

          
                </div>
              </div>
              <div class="col align-self-start">
                <div class="col-md-auto">
                  <div class="container-md">
                    <a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement" target="_black">BVI-Lowlight datasets</a> 
                    <a href='https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement'><img src="img/bvi-lowlight.jpg" width="100%" height="20%" alt=""></a>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
       
        <hr />
        <div class="container-md">
          <h2 id="projects">Projects</h2>
          <div class="researchlist">
            <div class="row">
            <div class="row vertical-align">
              <div class="col-md-auto">
                <div class="container-md">
            <h5>Production Workflow for Challenging Environments</h5>
           <ul>
            <li><a href="https://pui-nantheera.github.io/research/CIC/colorization_denoising.html">Contextual Video Enhancement</a></li>
            <li><a href="https://pui-nantheera.github.io/research/CIC/low_light_image_enhancement.html">Low-Light Enhancement and Denoising</a></li>
            <li><a href="https://pui-nantheera.github.io/research/CIC/MyUnderwaterWorld.html">Underwater Enhancement & 3D Representation</a></li>
            <li><a href="https://pui-nantheera.github.io/research/Heathaze/CLEAR.html">Atmospheric Turbulence Removal [Model-based]</a></li>
            <li><a href="https://pui-nantheera.github.io/research/Heathaze/DeepCLEAR.html">Atmospheric Turbulence Removal [AI-based]</a></li>
            <li><a href="https://pui-nantheera.github.io/research/Palantir/depth_estimation.html">Fast Depth Estimation for View Synthesis</a></li>
           </ul>
           <h5>Medical and Biological Image Computing</h5>
           <ul>
            <li><a href="https://pui-nantheera.github.io/research/MedImages/BLines.html">B-Line Quantification in Lung Ultrasound Images</a></li>
            <li><a href="https://pui-nantheera.github.io/research/MedImages/RetinalImages.html">Computer Assisted Analysis of Ocular Imaging</a></li>
            <li><a href="https://pui-nantheera.github.io/research/MedImages/Registration.html">Multi-modal Medical Image Registration</a></li>
            <li><a href="https://icip2022challenge.piclab.ai/">Parasitic Egg Detection and Classification</li>
            <li><a href="https://pui-nantheera.github.io/research/Microscopy/RBC.html">Deep Learning for Computational Microscopy</a></li>
           </ul>
           </div>
              </div>
              <div class="col align-self-start">
                <div class="col-md-auto">
                  <div class="container-md">
                   <h5>Computational Imaging in Remote Sensing</h5>
                   <ul>
                    <li><a href="https://pui-nantheera.github.io/research/NERC/volcano_deformation.html">Automated Alert System for Volcanic Unrest</a></li>
                    <li><a href="https://pui-nantheera.github.io/research/NERC/ground_deformation.html">Dynamic Ground Motion Map of the UK</a></li>
                    <li><a href="https://arxiv.org/pdf/2203.02407.pdf">Ground Movement Monitoring along the Rail Corridor</a></li>
                    <li><a href="https://ieeexplore.ieee.org/abstract/document/9163087">River Planform Extraction in SAR</a></li>
                   <li><a href="https://research-information.bris.ac.uk/en/publications/image-fusion-via-sparse-regularization-with-non-convex-penalties">Image Fusion</a></li>
                   </ul>
                   <h5>Computer Vision for Robotics</h5>
           <ul>
            <li><a href="https://seis.bristol.ac.uk/~eexna\research\Palantir.html">Real Time Inspection of Wind Turbine Blade Health</a></li>
            <li><a href="https://seis.bristol.ac.uk/~eexna\research\biovisualframework.html">Bio-inspired Visual Framework for Autonomous Locomotion</a></li>
            <li><a href="https://seis.bristol.ac.uk/~eexna\research\terrainTexture.html">Terrain Analysis for Robotics</a></li>
            <li><a href="https://www.researchgate.net/profile/Nantheera-Anantrasirichai/publication/307515702_Fixation_identification_for_low-sample-rate_mobile_eye_trackers/links/5ba3a3ffa6fdccd3cb660495/Fixation-identification-for-low-sample-rate-mobile-eye-trackers.pdf">Fixation Prediction</a></li>
           </ul>
                  </div>
                </div>
              </div>
            </div>
          </div>
      
            
            <div class="line_sep"></div>
            More projects and details: <a href="research.html">see here</a>

          </div>



          <h3></h3>
        </div>
        <hr />
        <div class="container-md">
          <h2 id="Publications">Publications</h2>
          For all my papers, see both google scholar and university site
          <ul>
            <li><a href="https://scholar.google.com/citations?user=40VEYswAAAAJ&hl=en">Google Scholar</a></li>
            <li><a href="https://research-information.bris.ac.uk/en/persons/n-anantrasirichai/publications/">research-information.bris.ac.uk</a></li>
          </ul>

          <div class="publicationlist">
            <h5>Selected papers</h5>
            <ul>
              <li><a>Feature Denoising For Low-Light Instance Segmentation Using Weighted Non-Local Blocks</a>. J Lin, N Anantrasirichai, D Bull, ICASSP 2025 <pdf>[</pdf><a href="https://arxiv.org/pdf/2402.18307">PDF</a><pdf>]</pdf></li>
              <li><a>UW-GS: Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater Scene Reconstruction</a>. H Wang, N Anantrasirichai, F Zhang, D Bull, WACV 2025 <pdf>[</pdf><a href="https://arxiv.org/pdf/2410.01517">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://pui-nantheera.github.io/research/CIC/MyUnderwaterWorld.html">Project</a><pdf>]</pdf></li>
              <li><a>DeTurb: Atmospheric Turbulence Mitigation with Deformable 3D Convolutions and 3D Swin Transformers</a>. Z Zou, N Anantrasirichai, ACCV 2024 <pdf>[</pdf><a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Zou_DeTurb_Atmospheric_Turbulence_Mitigation_with_Deformable_3D_Convolutions_and_3D_ACCV_2024_paper.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://pui-nantheera.github.io/research/Heathaze/DeepCLEAR.html">Project</a><pdf>]</pdf></li>
              <li><a>TaGAT: Topology-Aware Graph Attention Network For Multi-modal Retinal Image Fusion</a>. X Tian, N Anantrasirichai, L Nicholson, A Achim. MICCAI 2024 <pdf>[</pdf><a href="https://arxiv.org/pdf/2407.14188">PDF</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://github.com/xintian-99/TaGAT">Code</a><pdf>]</pdf> [<a href='https://data.bris.ac.uk/data/dataset/1hvd8aw0g6l6g28fnub18hgse4'>Dataset</a>] [<a href='https://pui-nantheera.github.io/research/MedImages/RetinalImages.html'>Project</a>]</li>
              <li><a>Learning Ground Displacement Signals Directly from InSAR-Wrapped Interferograms</a>. L Moualla, A Rucci, G Naletto, N Anantrasirichai. Sensors. 2024 <pdf>[</pdf><a href="https://www.mdpi.com/1424-8220/24/8/2637">PDF</a><pdf>]</pdf> </li>
              <li><a>Parasitic Egg Detection and Classification in Low-cost Microscopic Images using Transfer Learning</a>. T Suwannaphong, S Chavana, S Tongsom, D Palasuwan, T H Chalidabhongse, and N Anantrasirichai. SN Computer Science. 2023 <pdf>[</pdf><a href="https://link.springer.com/article/10.1007/s42979-023-02406-8">PDF</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://zenodo.org/records/10437395">Dataset</a><pdf>]</pdf></li>
              <li><a>Current Advances in Computational Lung Ultrasound Imaging: A Review</a>. T. Yang, O. Karakuş, N. Anantrasirichai, and A. Achim.  IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control. 2023.<pdf>[</pdf><a href="https://arxiv.org/pdf/2103.11366.pdf">PDF</a><pdf>]</pdf> </li>
              <li><a>ICIP 2022 Challenge on Parasitic Egg Detection and Classification in Microscopic Images: Dataset, Methods and Results</a>. N Anantrasirichai, TH Chalidabhongse, D Palasuwan, K Naruenatthanaset, T Kobchaisawat, N Nunthanasup, K Boonpeng, X Ma,  and A Achim. IEEE International Conference on Image Processing. 2022. <pdf>[</pdf><a href="https://arxiv.org/pdf/2208.06063.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://ieee-dataport.org/competitions/parasitic-egg-detection-and-classification-microscopic-images">Dataset</a><pdf>]</pdf> <pdf>[</pdf><a target="_blank" href="https://icip2022challenge.piclab.ai/">Website</a><pdf>]</pdf> </li>
              <li><a>Detecting Ground Deformation in the Built Environment using Sparse Satellite InSAR data with a Convolutional Neural Network</a>. N. Anantrasirichai, J. Biggs, K. Kelevitz, Z. Sadeghi, T. Wright, J. Thompson, A. Achim and D. Bull.  IEEE Transactions on Geoscience and Remote Sensing. 2020.<pdf>[</pdf><a href="https://arxiv.org/pdf/2005.03221.pdf">PDF</a><pdf>]</pdf> [<a href="https://pui-nantheera.github.io/research/NERC/ground_deformation.html">Project</a>]</li>
              <li><a>Image fusion via sparse regularization with non-convex penalties</a>. N. Anantrasirichai, R. Zheng, I. Selesnick and A. Achim.  Pattern Recognition Letters. 2020. <pdf>[</pdf><a href="https://arxiv.org/pdf/1905.09645.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://github.com/pui-nantheera/Image-Fusion-via-Sparse-Regularization">CODE</a><pdf>]</pdf> </pdf></li>
              <li><a>River Planform Extraction From High-Resolution SAR Images Via Generalised Gamma Distribution Superpixel Classification</a>. O. Pappas, N. Anantrasirichai, A. Achim and B. Adams. IEEE Transactions on Geoscience and Remote Sensing. 2020.<pdf>[</pdf><a href="https://ieeexplore.ieee.org/document/9163087">PDF</a><pdf>]</pdf> </li>
              <li><a>Detection of Line Artefacts in Lung Ultrasound Images of COVID-19 Patients via Non-Convex Regularization</a>. O. Karakuş, N. Anantrasirichai, A. Aguersif, S. Silva, A. Basarab and A Achim. IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control. 2020.<pdf>[</pdf><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9165792">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://ieeexplore.ieee.org/document/9165792" target="_blank">BibTeX</a><pdf>]</pdf> [<a href="https://github.com/oktaykarakus/QuantLUS-CPS-v1.0" target="_blank">CODE</a>]</li>
              <li><a>The Application of Convolutional Neural Networks to Detect Slow, Sustained Deformation in InSAR Timeseries</a>. N. Anantrasirichai, J. Biggs, F. Albino, and David Bull. Geophysical Research Letters. 2019. <pdf>[</pdf><a href="https://arxiv.org/pdf/1909.02321.pdf">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019GL084993" target="_blank">BibTeX</a><pdf>]</pdf> [<a href="https://seis.bristol.ac.uk/~eexna\research\volcanicUnrest.html">Project</a>]</li>
              <li><a>A Deep Learning Approach to Detecting Volcano Deformation from Satellite Imagery using Synthetic Datasets</a>. N. Anantrasirichai, J. Biggs, F. Albino, and David Bull. Remote Sensing of Environment. 2019. <pdf>[</pdf><a href="https://arxiv.org/abs/1905.07286">PDF</a><pdf>]</pdf> <pdf>[</pdf><a href="https://www.sciencedirect.com/science/article/pii/S003442571930183X" target="_blank">BibTeX</a><pdf>]</pdf> [<a href="https://github.com/pui-nantheera/volcano_deform_detection" target="_blank">CODE</a>] [<a href="https://seis.bristol.ac.uk/~eexna\research\volcanicUnrest.html">Project</a>]</li>
            </ul>
          </div>
          <div class="line_sep"></div>
          <a href="publications.html">More papers: see here</a>
        </div>
        <hr />
        <div class="container-md">
          <h2 id="download">Download</h2>
          <h5>Datasets</h5>
          <ul>
            <li><a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement">BVI-RLV</a>: Fully Registered Low-Light Videos</li>
            <li><a href="https://ieee-dataport.org/open-access/bvi-lowlight-fully-registered-datasets-low-light-image-and-video-enhancement">BVI-LOWLIGHT</a>: Dataset for  Low-Light Image Denoising [<a href="https://www.sciencedirect.com/science/article/pii/S016516842300155X">Paper</a>]</li>
              <li><a href="https://zenodo.org/records/13737763">BVI-Turb</a>: Atmospheric Turbulence Dataset  </li>
              <li><a href="https://zenodo.org/records/11093417">BVI-Coral</a>: Underwater scenes for 3D reconstruction [<a href="https://arxiv.org/pdf/2410.01517">Paper</a>]</li>
              <li><a href='https://data.bris.ac.uk/data/dataset/1hvd8aw0g6l6g28fnub18hgse4'>OCT2Confocal</a>: in-vivo OCT and ex-vivo confocal retinal images [<a href="https://www.cambridge.org/core/journals/biological-imaging/article/quest-for-early-detection-of-retinal-disease-3d-cycleganbased-translation-of-optical-coherence-tomography-into-confocal-microscopy/64E48453A70A32A947910B663CF4E665">Paper</a>]</li>
              <li><a href='https://ieee-dataport.org/competitions/parasitic-egg-detection-and-classification-microscopic-images'>ICIP 2022 Challenge</a>: Parasitic Egg Detection and Classification in Microscopic Images [<a href="https://ieeexplore.ieee.org/document/9897267">Paper</a>]</li>
              <li><a href="https://zenodo.org/records/10437395">Chula-parasitic-eggs</a>: Parasitic Egg Detection and Classification in Low-cost Microscopic Images [<a href="https://link.springer.com/article/10.1007/s42979-023-02406-8">Paper</a>]</li>
              <li><a href="https://zenodo.org/records/13254978">LICS Dataset</a> for Volcanic Deformation Classification [<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018JB015911">Paper</a>]</li>
            </ul>
          <a href="https://seis.bristol.ac.uk/~eexna/download.html">Find more code and datasets here.</a>
        </div>
      </div>
    </div>
  </body>

  </html>
